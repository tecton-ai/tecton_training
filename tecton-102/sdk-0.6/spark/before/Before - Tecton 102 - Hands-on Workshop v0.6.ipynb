{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10784bbd-45b2-4137-96ca-ad8e220ad183",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:16:59.205540Z",
     "iopub.status.busy": "2023-04-27T23:16:59.205292Z",
     "iopub.status.idle": "2023-04-27T23:16:59.263055Z",
     "shell.execute_reply": "2023-04-27T23:16:59.262545Z",
     "shell.execute_reply.started": "2023-04-27T23:16:59.205514Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Databricks\n",
    "# dbutils.widgets.text('Tecton API Key', defaultValue='')\n",
    "# dbutils.widgets.text('API endpoint', defaultValue='')\n",
    "\n",
    "# TECTON_API_KEY = dbutils.widgets.get('Tecton API Key')\n",
    "# TECTON_CLUSTER = dbutils.widgets.get('API endpoint')\n",
    "\n",
    "# For EMR\n",
    "TECTON_API_KEY='<your api key here>'\n",
    "TECTON_CLUSTER='<your cluster.tecton.ai here>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae2b392e-0ff2-4d02-bc31-0580712c9148",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Welcome to Tecton!\n",
    "\n",
    "We've designed this notebook to introduce you to the basic workflow of creating a feature view in Tecton, testing it, and pushing it to your Tecton instance when you're done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8491bef6-a62d-474c-a03d-7e9761429322",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "# Initializing your session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "033d3f24-0efa-41c2-9672-8cb2a28b8435",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "## Logging into Tecton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1f011d5-982e-48d9-a0d9-0426d0b4cdc0",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:13:39.289177Z",
     "iopub.status.busy": "2023-04-27T23:13:39.288799Z",
     "iopub.status.idle": "2023-04-27T23:13:40.610939Z",
     "shell.execute_reply": "2023-04-27T23:13:40.610103Z",
     "shell.execute_reply.started": "2023-04-27T23:13:39.289138Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tecton\n",
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n",
    "\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38168c70-099a-4ad0-9314-f0b600c0c506",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "# Create feature view from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f3eda30-f49b-4cb0-bbb9-e9d5269b6b5b",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:13:52.527945Z",
     "iopub.status.busy": "2023-04-27T23:13:52.527716Z",
     "iopub.status.idle": "2023-04-27T23:13:52.596199Z",
     "shell.execute_reply": "2023-04-27T23:13:52.595669Z",
     "shell.execute_reply.started": "2023-04-27T23:13:52.527921Z"
    }
   },
   "outputs": [],
   "source": [
    "from tecton import (\n",
    "  BatchSource,\n",
    "  FileConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd222ce2-42d1-4b00-8a2a-8eac190bf79d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aa7c9d9-bd89-4288-930a-93b30058e7f1",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:13:53.418839Z",
     "iopub.status.busy": "2023-04-27T23:13:53.418614Z",
     "iopub.status.idle": "2023-04-27T23:13:53.482170Z",
     "shell.execute_reply": "2023-04-27T23:13:53.481626Z",
     "shell.execute_reply.started": "2023-04-27T23:13:53.418815Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions_batch = BatchSource(\n",
    "    name='transactions_batch',\n",
    "    batch_config=FileConfig(\n",
    "        timestamp_field=\"timestamp\",\n",
    "        uri=\"s3://tecton.ai.public/data/fraud_mini/transactions/transactions.parquet\",\n",
    "        file_format=\"parquet\"\n",
    "    ),\n",
    "    owner='jack@tecton.ai',\n",
    "    tags={'release': 'production'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5fe36a5-e067-4c23-99ee-bfa78fb70e50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Inspect data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f2216ae-c591-4deb-b176-e941f7093723",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create the entity and feature view logic\n",
    "\n",
    "Now that we have our data source created, we can now create our feature view, which contains both the transformation logic we want to run on our data source as well as orchestration parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be024927-0ef8-4ac1-9f57-7d4010bcddad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "An **entity** just tells Tecton what the join key is, in this case the `USER_ID` column. Tecton will check to make sure this column(s) exist after running our transformation logic, so we need to make sure we return a `USER_ID` column from our feature view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e6849eb-428e-4d92-a7f2-e9bb58604d65",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A **batch_feature_view** ties it all together: we specify the data source, entity, and call the transformation we defined above, plus we add in what storage layer Tecton should write this data to and how frequently Tecton should run this logic against new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a3884e5-2618-481b-b138-a0fb000cd2be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tecton import (\n",
    "  batch_feature_view,\n",
    "  Aggregation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d5356cf-c545-486a-8f0b-b990346d07fc",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add feature view code from workshop here\n",
    "@batch_feature_view(\n",
    "    sources=[transactions_batch],\n",
    "    entities=[user],\n",
    "    mode='spark_sql',\n",
    "    aggregations=[\n",
    "        Aggregation(column='transaction', function='count', time_window=timedelta(hours=24)),\n",
    "        Aggregation(column='transaction', function='count', time_window=timedelta(hours=72))\n",
    "    ],\n",
    "    aggregation_interval=timedelta(hours=24),\n",
    "    online=True,\n",
    "    offline=True,\n",
    "    feature_start_time=datetime(2020, 10, 10)\n",
    ")\n",
    "def user_transaction_counts(transactions_batch):\n",
    "    return f'''\n",
    "        SELECT\n",
    "        nameOrig AS user_id,\n",
    "        1 AS transaction,\n",
    "        timestamp\n",
    "        FROM {transactions_batch}\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5bb3117-083a-4130-9882-98a46f5462ac",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "## Test our feature view\n",
    "\n",
    "Now let's see what kind of data we get back from our feature view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bab85749-0f8e-4365-96cc-0ab74634ae88",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Our output is a Tecton dataframe and we're going to save this as a Snowpark dataframe. [Snowpark](https://www.snowflake.com/en/data-cloud/snowpark/) is like Spark on Snowflake (get it?) and the Spark dataframe methods you might be familiar with you can use here. Working in Snowpark is a good idea if you're going to be examining a Tecton query that could be bringing back a large set of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cc7f927-f371-4e1a-b5cd-1e8aa10e184f",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "# Append our feature view to a remote feature service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08687c72-0c8f-41be-96b6-2c5a1c6e6270",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Log in to a remote cluster\n",
    "\n",
    "We're going to log into our cluster using a Tecton API key linked to a service account. This service account needs to be created and granted at least Consumer access to the workspace we're trying to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df46d98-318a-4fe4-a197-def29188082c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tecton_api_key = dbutils.widgets.get('Tecton API Key')\n",
    "tecton_api_endpoint = dbutils.widgets.get('API endpoint')\n",
    "tecton.set_credentials(tecton_url=f'https://{tecton_api_endpoint}/api', tecton_api_key=tecton_api_key)\n",
    "tecton.test_credentials()\n",
    "print(tecton.who_am_i())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5670a781-8c30-4b0f-a547-14f4013d3ef3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Get our feature service remotely from Tecton\n",
    "\n",
    "We only created the feature view above from scratch because it's worth seeing what the whole flow looks like. In many cases, however, you want to extend or modify an existing feature service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fe169b3-b233-4085-913a-745ac77c204e",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spine = pd.DataFrame([\n",
    "    [\"C151068873\", pd.Timestamp('2023-03-29 00:00Z'), True],\n",
    "    [\"C658286540\", pd.Timestamp('2023-03-28 00:00Z'), False],\n",
    "], columns=['user_id', 'timestamp', 'is_fraud'])\n",
    "\n",
    "spine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0150da1-285f-4c48-83f1-b203242448ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Now let's extend that remote feature service with a locally-developed feature view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feed51d0-84f4-4814-87c1-1a590cfafc37",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@batch_feature_view(\n",
    "    sources=[tecton.FilteredSource(ws.get_data_source('transactions_batch'))],\n",
    "    entities=[ws.get_entity('fraud_user')],\n",
    "    mode='spark_sql',\n",
    "    online=False,\n",
    "    offline=False,\n",
    "    feature_start_time=datetime(2022, 4, 1),\n",
    "    batch_schedule=timedelta(days=1),\n",
    "    ttl=timedelta(days=30),\n",
    "    description='Last user transaction amount (batch calculated)'\n",
    ")\n",
    "def last_transaction_amount_batch(transactions_batch):\n",
    "    return f'''\n",
    "        SELECT\n",
    "            timestamp,\n",
    "            nameOrig AS user_id,\n",
    "            amount\n",
    "        FROM\n",
    "            {transactions_batch}\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38f17d93-aa97-48c7-b08d-0a096899c55c",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "# Apply our new feature view + feature service into our repository!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all of our development has been done locally in our Jupyter instance. We’re happy with our work so far and we want to push it to a workspace in Tecton so we can do additional integration testing and/or push to production:\n",
    "\n",
    "The steps are:\n",
    "\n",
    "* Copy and paste the feature view and feature service definitions into the repository’s .py files\n",
    "* Log into your cluster (`tecton login https://...`) and select or create a workspace (`tecton workspace create ...` or `tecton workspace select ...`)\n",
    "* Run a `tecton plan` to inspect your features\n",
    "* Once satisfied, run tecton apply to push your features to the workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test our feature service!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e01892cc-3915-4347-81f8-1d16410e9acf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "So far, all of our development has been done locally in our Jupyter instance. We're happy with our work so far and we want to push it to a workspace in Tecton so we can do additional integration testing and/or push to production:\n",
    "\n",
    "The steps are:\n",
    "* Copy and paste the feature view and feature service definitions into the repository's `.py` files\n",
    "* Log into your cluster (`tecton login https://...`) and select or create a workspace (`tecton workspace create ...` or `tecton workspace select ...`)\n",
    "* Run a `tecton plan` to inspect your features\n",
    "* Once satisfied, run `tecton apply` to push your features to the workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67859d7e-6191-49c9-808a-481ca29e8427",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now let's test our feature service!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28e73dc1-2fbb-4305-9ff1-0f5b4a425f7d",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "# Get real-time features from your REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33fa1a9f-5b06-47c6-8826-7ace62454a2a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Once you've tested your features to make sure they work (and check out our Unit Testing capabilities!), if you need real-time serving, there are just a couple more steps:\n",
    "\n",
    "* Create or select a **live** workspace. This is a workspace with materialization switched on.\n",
    "* Wait for your features to materialize. You can check the Web UI for more details here.\n",
    "* Create or use a service account and grant it at least `Consumer` level privileges\n",
    "* Use the API key associated with the service account to retrieve features.\n",
    "\n",
    "You can use any language to retrieve features, since it's just a REST API call. We suggest using native http requests libraries in your language (such as `requests` perhaps with `asyncio` with Python), or if you're on Java, check out our high-performance REST API client [here](https://github.com/tecton-ai/tecton-http-client-java) (also available on maven)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48ce974-aa28-4bf8-bf61-b0967ca02b56",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:13:58.081982Z",
     "iopub.status.busy": "2023-04-27T23:13:58.081742Z",
     "iopub.status.idle": "2023-04-27T23:13:58.147550Z",
     "shell.execute_reply": "2023-04-27T23:13:58.147002Z",
     "shell.execute_reply.started": "2023-04-27T23:13:58.081957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f646548e-b8e6-4fc8-a4c5-dd674ecbc5eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's formulate the request data packet. You can use our [API reference documentation](https://docs.tecton.ai/http-api) and [this docs page](https://docs.tecton.ai/docs/reading-feature-data/reading-feature-data-for-inference/reading-online-features-for-inference-using-the-http-api/#metadata-options-for-the-http-api) for information on the metadata you can retrieve on your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f8359dd-1b00-4946-a7a3-25e3ccdde2a4",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:14:21.975459Z",
     "iopub.status.busy": "2023-04-27T23:14:21.975227Z",
     "iopub.status.idle": "2023-04-27T23:14:22.039098Z",
     "shell.execute_reply": "2023-04-27T23:14:22.038436Z",
     "shell.execute_reply.started": "2023-04-27T23:14:21.975434Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_data = json.dumps(\n",
    "    {\n",
    "        'params': {\n",
    "            'feature_service_name': 'fraud_detection_feature_service',\n",
    "            'join_key_map': {\n",
    "                'user_id': 'user_724235628997',\n",
    "                'merchant': 'fraud_Crona and Sons',\n",
    "            },\n",
    "            'request_context_map': {\n",
    "              'amt': 167.11\n",
    "            },\n",
    "            'workspace_name': 'prod',\n",
    "            'metadata_options': {\n",
    "                \"include_names\": True,\n",
    "                \"include_effective_times\": True,\n",
    "                \"include_data_types\": True,\n",
    "                \"include_slo_info\": True,\n",
    "                'include_serving_status': True\n",
    "            } \n",
    "        }\n",
    "    }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b017e8c-cd80-44eb-b9a5-88e8386b9dfa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's make the post request (we're reading the `REST_API_KEY` variable from the .env file and/or environment variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bf93a42-cfcd-40ef-bfa6-a1803307cccf",
     "showTitle": false,
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T23:14:22.919253Z",
     "iopub.status.busy": "2023-04-27T23:14:22.919026Z",
     "iopub.status.idle": "2023-04-27T23:14:23.190714Z",
     "shell.execute_reply": "2023-04-27T23:14:23.190083Z",
     "shell.execute_reply.started": "2023-04-27T23:14:22.919229Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = requests.post(\n",
    "    url=f\"https://{TECTON_CLUSTER}/api/v1/feature-service/get-features\",\n",
    "    headers={\n",
    "        'Authorization': f\"Tecton-key {TECTON_API_KEY}\"\n",
    "    },\n",
    "    data=request_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0578c02-d84d-4fa3-83c6-34e0f7a0a5aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now we examine the output"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3665980919140617,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": [
     {
      "breakBefore": false,
      "name": "Tecton API Key",
      "width": 153
     }
    ]
   },
   "notebookName": "Tecton 102 - Hands-on Workshop (Spark Databricks 0.6)",
   "notebookOrigID": 2196188861519739,
   "widgets": {
    "API endpoint": {
     "currentValue": "",
     "nuid": "55773a7b-c243-48d2-85e8-f7b4c7e8f8cf",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "API endpoint",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "Tecton API Key": {
     "currentValue": "",
     "nuid": "6dbe0670-08ca-49d6-82ef-0c91e28570f8",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "Tecton API Key",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aba455fa597a7c56079ecbcca10fe0ea0e36ccea185e88cba0d5f6274cb64de0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
